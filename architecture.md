# Mini-Chatbox RAG Agent - Architecture

## System Overview

The Mini-Chatbox RAG Agent is a sophisticated conversational AI system that combines task decomposition, retrieval-augmented generation, multimodal processing, and intelligent memory management with flexible agent scripting capabilities.

## Project Status

### âœ… Completed Components
- **Foundation Setup**: Full TypeScript environment with testing, linting, and Docker support
- **Project Structure**: Organized directory structure for scalable development
- **Docker Environment**: Development and production Docker configurations
- **Basic Documentation**: README, environment configuration, and initial architecture

### ğŸš§ In Progress
- **Core Backend Services**: Setting up Express server with WebSocket support
- **Database Schemas**: Designing TypeORM entities for PostgreSQL
- **Frontend Shell**: Basic React application structure

### ğŸ“‹ Next Steps
1. Implement basic API endpoints and WebSocket handlers
2. Create database models and migrations
3. Set up authentication and session management
4. Build initial UI components

## High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      User Interface                          â”‚
â”‚                    (Chatbox Frontend)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  API Gateway / Router                        â”‚
â”‚              (WebSocket + REST Endpoints)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Core Orchestrator                            â”‚
â”‚         (Task Manager & Agent Coordinator)                   â”‚
â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚          â”‚          â”‚          â”‚          â”‚
   â–¼          â–¼          â–¼          â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Task â”‚ â”‚   MCP   â”‚ â”‚ RAG  â”‚ â”‚  Multi  â”‚ â”‚  Memory  â”‚
â”‚Divisionâ”‚ â”‚ Server â”‚ â”‚Systemâ”‚ â”‚  Modal  â”‚ â”‚  System  â”‚
â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Docker Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Docker Host System                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                   Docker Compose Network                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚   Nginx     â”‚ â”‚  Frontend    â”‚ â”‚    Backend API         â”‚â”‚
â”‚ â”‚   Reverse   â”‚ â”‚  Container   â”‚ â”‚    Container           â”‚â”‚
â”‚ â”‚   Proxy     â”‚ â”‚  (React/Vue) â”‚ â”‚    (Node.js)           â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚  PostgreSQL â”‚ â”‚    Redis     â”‚ â”‚   Vector DB            â”‚â”‚
â”‚ â”‚  Container  â”‚ â”‚  Container   â”‚ â”‚   (Qdrant/Weaviate)   â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚              Shared Volumes & Networks                   â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Core Components

### 1. Task Division System

**Purpose**: Breaks down complex user requests into manageable subtasks.

**Architecture**:
```
Task Division Module
â”œâ”€â”€ Task Parser
â”‚   â”œâ”€â”€ Natural Language Understanding
â”‚   â”œâ”€â”€ Intent Recognition
â”‚   â””â”€â”€ Dependency Analysis
â”œâ”€â”€ Task Queue
â”‚   â”œâ”€â”€ Priority Queue Implementation
â”‚   â”œâ”€â”€ Task State Manager
â”‚   â””â”€â”€ Concurrency Controller
â””â”€â”€ Task Executor
    â”œâ”€â”€ Subtask Generator
    â”œâ”€â”€ Progress Tracker
    â””â”€â”€ Result Aggregator
```

**Key Technologies**:
- Abstract Syntax Tree (AST) for task representation
- Graph-based dependency resolution
- Priority queue with dynamic reordering

### 2. MCP (Model Context Protocol) Integration

**Purpose**: Enables standardized communication with various AI models and tools.

**Architecture**:
```
MCP Integration Layer
â”œâ”€â”€ MCP Server
â”‚   â”œâ”€â”€ Protocol Handler
â”‚   â”œâ”€â”€ Tool Registry
â”‚   â””â”€â”€ Session Manager
â”œâ”€â”€ MCP Client
â”‚   â”œâ”€â”€ Connection Pool
â”‚   â”œâ”€â”€ Request/Response Handler
â”‚   â””â”€â”€ Error Recovery
â””â”€â”€ Tool Adapters
    â”œâ”€â”€ Built-in Tools
    â”œâ”€â”€ Custom Tool Interface
    â””â”€â”€ Tool Validation
```

**Key Features**:
- Bidirectional streaming support
- Tool discovery and registration
- Automatic retry with exponential backoff
- Claude Desktop compatible configuration format
- Automatic tool synchronization from backend
- Periodic refresh to keep tools up to date

**Configuration Format** (Claude Desktop Compatible):
```json
{
  "mcpServers": {
    "filesystem": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-filesystem", "/path"]
    },
    "github": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-github"],
      "env": {
        "GITHUB_PERSONAL_ACCESS_TOKEN": "your-token"
      }
    }
  }
}
```

**Key Features**:
- Uses official Claude Desktop configuration format
- All servers use stdio transport (standard input/output)
- Server ID becomes the server name
- Environment variables supported via `env` field
- No custom properties needed (type, name, enabled are automatic)

### 3. RAG (Retrieval-Augmented Generation) System

**Purpose**: Enhances responses with relevant contextual information from a knowledge base.

**Architecture**:
```
RAG Pipeline
â”œâ”€â”€ Document Ingestion
â”‚   â”œâ”€â”€ Document Loaders (PDF, TXT, MD, etc.)
â”‚   â”œâ”€â”€ Chunking Strategy
â”‚   â””â”€â”€ Metadata Extraction
â”œâ”€â”€ Embedding Generation
â”‚   â”œâ”€â”€ Text Embedder
â”‚   â”œâ”€â”€ Batch Processing
â”‚   â””â”€â”€ Embedding Cache
â”œâ”€â”€ Vector Store
â”‚   â”œâ”€â”€ Index Management
â”‚   â”œâ”€â”€ Similarity Search
â”‚   â””â”€â”€ Hybrid Search (Vector + Keyword)
â””â”€â”€ Context Assembly
    â”œâ”€â”€ Relevance Scoring
    â”œâ”€â”€ Context Window Optimization
    â””â”€â”€ Source Attribution
```

**Storage Options**:
- Primary: Pinecone/Weaviate/Qdrant for vector storage
- Secondary: PostgreSQL with pgvector for hybrid search
- Cache: Redis for embedding cache

### 4. Multimodal Processing

**Purpose**: Handles various input types beyond text.

**Architecture**:
```
Multimodal Engine
â”œâ”€â”€ Image Processing
â”‚   â”œâ”€â”€ Image Upload Handler
â”‚   â”œâ”€â”€ Vision Model Integration
â”‚   â”œâ”€â”€ OCR Pipeline
â”‚   â””â”€â”€ Image Embedding Generator
â”œâ”€â”€ Video Processing
â”‚   â”œâ”€â”€ Frame Extraction
â”‚   â”œâ”€â”€ Scene Analysis
â”‚   â””â”€â”€ Temporal Understanding
â””â”€â”€ Audio Processing
    â”œâ”€â”€ Speech-to-Text
    â”œâ”€â”€ Audio Analysis
    â””â”€â”€ Emotion Detection
```

**Integration Points**:
- OpenAI Vision API / Claude Vision
- Whisper for audio transcription
- Custom ML models for specialized tasks

### 5. Context Memory System

**Purpose**: Maintains conversation context and user preferences across sessions.

**Architecture**:
```
Memory Management
â”œâ”€â”€ Short-term Memory
â”‚   â”œâ”€â”€ Conversation Buffer
â”‚   â”œâ”€â”€ Active Context Window
â”‚   â””â”€â”€ Recent Interactions Cache
â”œâ”€â”€ Long-term Memory
â”‚   â”œâ”€â”€ User Profile Store
â”‚   â”œâ”€â”€ Conversation History DB
â”‚   â””â”€â”€ Learned Preferences
â””â”€â”€ Memory Operations
    â”œâ”€â”€ Contextual Retrieval
    â”œâ”€â”€ Memory Consolidation
    â”œâ”€â”€ Forgetting Mechanism
    â””â”€â”€ Memory Search
```

**Storage Strategy**:
- In-memory: Current conversation context
- Redis: Recent conversations and quick access
- PostgreSQL: Long-term conversation history
- Vector DB: Semantic memory search

### 6. Agent Script System

**Purpose**: Enables rapid creation and deployment of specialized agents.

**Architecture**:
```
Agent Framework
â”œâ”€â”€ Script Engine
â”‚   â”œâ”€â”€ DSL Parser
â”‚   â”œâ”€â”€ Script Validator
â”‚   â””â”€â”€ Runtime Environment
â”œâ”€â”€ Agent Registry
â”‚   â”œâ”€â”€ Agent Templates
â”‚   â”œâ”€â”€ Capability Mapping
â”‚   â””â”€â”€ Version Control
â””â”€â”€ Orchestration Layer
    â”œâ”€â”€ Agent Scheduler
    â”œâ”€â”€ Inter-agent Communication
    â””â”€â”€ Resource Management
```

**Script Format Example**:
```yaml
agent:
  name: "Research Assistant"
  capabilities:
    - web_search
    - summarization
    - citation_generation
  triggers:
    - intent: "research"
    - keywords: ["find", "search", "investigate"]
  workflow:
    - search_web
    - extract_relevant_info
    - generate_summary
    - add_citations
```

## Data Flow

1. **User Input** â†’ API Gateway â†’ Core Orchestrator
2. **Task Analysis** â†’ Task Division â†’ Subtask Queue
3. **Context Gathering** â†’ Memory System + RAG Retrieval
4. **Processing** â†’ Agent Selection â†’ MCP Tools â†’ Response Generation
5. **Response** â†’ Context Update â†’ Memory Storage â†’ User Output

## Technology Stack

### Backend
- **Language**: Node.js/TypeScript (primary) or Python
- **Framework**: Express.js/Fastify or FastAPI
- **Real-time**: Socket.io or native WebSockets
- **Queue**: Redis + Bull Queue

### Storage
- **Primary DB**: PostgreSQL
- **Vector DB**: Pinecone/Weaviate/Qdrant
- **Cache**: Redis
- **File Storage**: S3-compatible storage

### AI/ML
- **LLMs**: OpenAI GPT-4, Claude, local models via Ollama
- **Embeddings**: OpenAI Ada, Sentence Transformers
- **Vision**: OpenAI Vision, CLIP
- **Speech**: Whisper, Azure Speech Services

### Infrastructure
- **Container**: Docker
- **Orchestration**: Kubernetes (for scale)
- **Monitoring**: Prometheus + Grafana
- **Logging**: ELK Stack or Loki

## Implementation Roadmap

### Phase 1: Core Infrastructure (Current)
- âœ… Project setup and configuration
- âœ… Docker environment
- â³ Basic API structure
- â³ Database setup
- â³ Authentication system

### Phase 2: Core Features
1. **Task Division System**
   - Task parser with LangChain integration
   - Bull queue implementation
   - Task dependency graph
   
2. **MCP Integration**
   - MCP server implementation
   - Tool registration system
   - Protocol handlers

3. **RAG System**
   - Document ingestion pipeline
   - Vector database integration (Qdrant)
   - Semantic search implementation

### Phase 3: Advanced Features
1. **Multimodal Support**
   - Image processing with Sharp
   - Audio transcription with Whisper API
   - Video frame extraction

2. **Memory System**
   - Conversation history storage
   - Context window management
   - Memory retrieval algorithms

3. **Agent Scripts**
   - YAML-based agent definitions
   - Hot-reload system
   - Agent orchestration

## Docker Implementation

### Container Strategy

#### 1. Multi-Stage Dockerfile
```dockerfile
# Stage 1: Dependencies
FROM node:18-alpine AS deps
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production

# Stage 2: Build
FROM node:18-alpine AS builder
WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build

# Stage 3: Production
FROM node:18-alpine AS runner
WORKDIR /app
RUN addgroup -g 1001 -S nodejs
RUN adduser -S nodejs -u 1001
COPY --from=deps --chown=nodejs:nodejs /app/node_modules ./node_modules
COPY --from=builder --chown=nodejs:nodejs /app/dist ./dist
USER nodejs
EXPOSE 3000
CMD ["node", "dist/index.js"]
```

#### 2. Docker Compose Configuration
```yaml
version: '3.8'

services:
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - backend
      - frontend
    networks:
      - chatbox-network

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://user:pass@postgres:5432/chatbox
      - REDIS_URL=redis://redis:6379
      - VECTOR_DB_URL=http://qdrant:6333
    depends_on:
      - postgres
      - redis
      - qdrant
    networks:
      - chatbox-network
    volumes:
      - ./agent-scripts:/app/agent-scripts
      - uploads:/app/uploads

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    environment:
      - REACT_APP_API_URL=http://backend:3000
    networks:
      - chatbox-network

  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_USER=chatbox
      - POSTGRES_PASSWORD=secret
      - POSTGRES_DB=chatbox
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - chatbox-network

  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data
    networks:
      - chatbox-network

  qdrant:
    image: qdrant/qdrant:latest
    volumes:
      - qdrant-data:/qdrant/storage
    networks:
      - chatbox-network

volumes:
  postgres-data:
  redis-data:
  qdrant-data:
  uploads:

networks:
  chatbox-network:
    driver: bridge
```

#### 3. Development Docker Compose
```yaml
version: '3.8'

services:
  backend-dev:
    build:
      context: ./backend
      dockerfile: Dockerfile.dev
    volumes:
      - ./backend:/app
      - /app/node_modules
    environment:
      - NODE_ENV=development
    command: npm run dev
    ports:
      - "3000:3000"
      - "9229:9229" # Debug port

  frontend-dev:
    build:
      context: ./frontend
      dockerfile: Dockerfile.dev
    volumes:
      - ./frontend:/app
      - /app/node_modules
    environment:
      - CHOKIDAR_USEPOLLING=true
    command: npm start
    ports:
      - "3001:3000"
```

### Docker Best Practices

1. **Security**
   - Run containers as non-root user
   - Use official base images
   - Scan images for vulnerabilities
   - Implement secrets management

2. **Optimization**
   - Minimize layers in Dockerfile
   - Use .dockerignore effectively
   - Leverage build cache
   - Optimize image size

3. **Networking**
   - Use custom networks for isolation
   - Implement service discovery
   - Configure health checks

4. **Data Management**
   - Use named volumes for persistence
   - Implement backup strategies
   - Handle database migrations

### Quick Start Guide

```bash
# Clone repository
git clone https://github.com/your-org/mini-chatbox-rag-agent
cd mini-chatbox-rag-agent

# Install dependencies (for local development)
make install

# Start development environment
make dev

# Or use Docker directly
docker-compose -f docker-compose.dev.yml up -d

# View logs
make logs-dev

# Run tests
make test

# Stop all services
make stop
```

### Development Workflow

1. **Backend Development**
   ```bash
   cd backend
   npm run dev    # Starts with hot-reload
   npm test       # Run tests
   npm run lint   # Check code quality
   ```

2. **Frontend Development**
   ```bash
   cd frontend
   npm run dev    # Starts Vite dev server
   npm test       # Run tests
   npm run build  # Production build
   ```

3. **Database Management**
   - Access pgAdmin at http://localhost:5050
   - Credentials: admin@chatbox.local / admin
   - Run migrations: `npm run migration:run`

4. **Vector Database**
   - Qdrant dashboard at http://localhost:6333/dashboard
   - Create collections via API or dashboard

## Security Considerations

1. **Authentication**: JWT-based auth with refresh tokens
2. **Authorization**: Role-based access control (RBAC)
3. **Data Encryption**: TLS in transit, AES-256 at rest
4. **Input Validation**: Comprehensive sanitization
5. **Rate Limiting**: Per-user and per-endpoint limits
6. **Audit Logging**: All actions logged with user context

## Scalability Design

1. **Horizontal Scaling**: Stateless services behind load balancer
2. **Caching Strategy**: Multi-level caching (CDN, Redis, application)
3. **Database Sharding**: User-based sharding for conversation data
4. **Async Processing**: Event-driven architecture with message queues
5. **Resource Pooling**: Connection pools for DB and external services

## Performance Targets

- **Response Time**: < 2s for simple queries, < 5s for complex RAG queries
- **Throughput**: 1000+ concurrent users
- **Availability**: 99.9% uptime
- **Memory Efficiency**: < 500MB per active session
- **Vector Search**: < 100ms for 1M vectors
- **Container Startup**: < 30s for full stack
- **Image Size**: < 200MB for production images

## Current Implementation Status

### Backend Structure
```
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts           # Entry point (to be created)
â”‚   â”œâ”€â”€ app.ts             # Express app setup (to be created)
â”‚   â”œâ”€â”€ config/            # Configuration management
â”‚   â”œâ”€â”€ controllers/       # Route handlers
â”‚   â”œâ”€â”€ services/          # Business logic
â”‚   â”œâ”€â”€ models/            # Database models
â”‚   â”œâ”€â”€ middleware/        # Express middleware
â”‚   â””â”€â”€ utils/             # Utility functions
â”œâ”€â”€ tests/                 # Test files
â””â”€â”€ package.json          # Dependencies configured
```

### Frontend Structure
```
frontend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.tsx          # Entry point (to be created)
â”‚   â”œâ”€â”€ App.tsx           # Main component (to be created)
â”‚   â”œâ”€â”€ components/       # Reusable components
â”‚   â”œâ”€â”€ pages/            # Page components
â”‚   â”œâ”€â”€ hooks/            # Custom React hooks
â”‚   â”œâ”€â”€ services/         # API client
â”‚   â””â”€â”€ utils/            # Utility functions
â”œâ”€â”€ public/               # Static assets
â””â”€â”€ package.json         # Dependencies configured
```

### Next Implementation Tasks
1. Create backend entry point with Express server
2. Set up TypeORM database connection
3. Implement basic authentication endpoints
4. Create frontend entry point and routing
5. Build initial chat interface components
6. Establish WebSocket connection for real-time messaging

## Docker Monitoring & Observability

### Container Metrics
```yaml
# docker-compose.monitoring.yml
services:
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    ports:
      - "9090:9090"

  grafana:
    image: grafana/grafana:latest
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
    ports:
      - "3000:3000"

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    ports:
      - "8080:8080"
```

### Health Checks
```dockerfile
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD node healthcheck.js || exit 1
```